{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functions import *\n",
    "import cmapy\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetest = True\n",
    "if savetest == True:\n",
    "    testorval = \"test\"\n",
    "    seis_path = 'seistest.npy'\n",
    "else:\n",
    "    testorval = \"val\"\n",
    "    seis_path = 'seismicval.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seis = np.load(seis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703 1537 3174\n"
     ]
    }
   ],
   "source": [
    "IL, Z, XL = seis.shape\n",
    "print(IL, Z, XL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height = Z\n",
    "im_width = XL\n",
    "splitsize = 96\n",
    "stepsize = 48 #overlap half\n",
    "overlapsize = splitsize-stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "3312\n",
      "69 69\n",
      "33\n",
      "1680\n",
      "71 72\n"
     ]
    }
   ],
   "source": [
    "horizontal_splits_number = int(np.ceil((im_width)/stepsize))\n",
    "print(horizontal_splits_number)\n",
    "width_after_pad = stepsize*horizontal_splits_number+2*overlapsize\n",
    "print(width_after_pad)\n",
    "left_pad = int((width_after_pad-im_width)/2)\n",
    "right_pad = width_after_pad-im_width-left_pad\n",
    "print(left_pad,right_pad)\n",
    "\n",
    "vertical_splits_number = int(np.ceil((im_height)/stepsize))\n",
    "print(vertical_splits_number)\n",
    "height_after_pad = stepsize*vertical_splits_number+2*overlapsize\n",
    "print(height_after_pad)\n",
    "top_pad = int((height_after_pad-im_height)/2)\n",
    "bottom_pad = height_after_pad-im_height-top_pad\n",
    "print(top_pad,bottom_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "horizontal_splits_number = horizontal_splits_number+1\n",
    "print(horizontal_splits_number)\n",
    "vertical_splits_number = vertical_splits_number+1\n",
    "print(vertical_splits_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "halfoverlapsize = int(overlapsize/2)\n",
    "print(halfoverlapsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n"
     ]
    }
   ],
   "source": [
    "print(len(seis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325992\n",
      "(96, 96)\n",
      "read images in 20.060105800628662 sec\n",
      "(325992, 96, 96)\n",
      "read images in 36.8176155090332 sec\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "X_list = []\n",
    "for i in range(0,len(seis),5):\n",
    "    img = seis[i]\n",
    "    X_list.extend(split_Image(img,True,top_pad,bottom_pad,left_pad,right_pad,splitsize,stepsize,vertical_splits_number,horizontal_splits_number))\n",
    "#     break\n",
    "print(len(X_list))\n",
    "print(X_list[0].shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))\n",
    "X = np.asarray(X_list)\n",
    "print(X.shape)\n",
    "print(\"read images in {} sec\".format(time.time()-t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "X = np.expand_dims(X,1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea from: https://www.kaggle.com/erikistre/pytorch-basic-u-net\n",
    "class faultsDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,preprocessed_images):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        self.images = preprocessed_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faults_dataset_test = faultsDataset(X)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=faults_dataset_test, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iou_threshold = 0.5\n",
    "model_name = \"unet\" # unet deeplab rcf\n",
    "currentpath = \"/sgai_overlap/\"\n",
    "mergemethod = \"smooth\" # smooth average crop\n",
    "device = torch.device(\"cuda\")\n",
    "if model_name == \"unet\":\n",
    "    from model_zoo.UNET import Unet\n",
    "    model = Unet()\n",
    "    print(\"use model Unet\")\n",
    "    modelname = \"unet_LRoverlap_0.5Loss12_0.5Loss3_addafterepoch4_seed1\"\n",
    "    best_model_fpath = '{}/models/{}.model'.format(currentpath,modelname) \n",
    "    save_path = '{}/overlap_clean_predictions/{}_{}emerge_{}'.format(currentpath,modelname,mergemethod,testorval)\n",
    "elif model_name == \"deeplab\":\n",
    "    from model_zoo.DEEPLAB.deeplab import DeepLab\n",
    "    model = DeepLab(backbone='mobilenet', num_classes=1, output_stride=16)\n",
    "    print(\"use model DeepLab\")\n",
    "    modelname = \"deeplab_withoutLRoverlap_paired_seed236\"\n",
    "    best_model_fpath = '{}/models/{}.model'.format(currentpath,modelname) \n",
    "    save_path = '{}/overlap_clean_predictions/{}_{}emerge_{}'.format(currentpath,modelname,mergemethod,testorval)\n",
    "elif model_name == \"rcf\":\n",
    "    from model_zoo.RCF import RCF\n",
    "    model = RCF()\n",
    "    print(\"use model RCF\")\n",
    "    modelname = \"rcf_LRoverlap_0.5Loss12_0.5Loss3_addafterepoch10_seed236\"\n",
    "    best_model_fpath = '{}/models/{}.model'.format(currentpath,modelname) \n",
    "    save_path = '{}/overlap_clean_predictions/{}_{}emerge_{}'.format(currentpath,modelname,mergemethod,testorval)\n",
    "print(best_model_fpath)\n",
    "print(save_path)\n",
    "model.load_state_dict(torch.load(best_model_fpath, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "summary(model, (1, splitsize, splitsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPPER_BOUND = 800\n",
    "LOWER_BOUND = 1300\n",
    "print(\"UPPER_BOUND\",UPPER_BOUND)\n",
    "print(\"LOWER_BOUND\",LOWER_BOUND)\n",
    "    \n",
    "def saveResults(save_path, test_loader):     \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    test_predictions = []\n",
    "    imageNo = -1\n",
    "    for images in test_loader:\n",
    "        images = Variable(images.cuda())\n",
    "        outputs = model(images)\n",
    "        y_preds = outputs\n",
    "        if model_name == \"rcf\":\n",
    "            y_preds = outputs[-1]\n",
    "        test_predictions.extend(y_preds.detach().cpu())\n",
    "        if len(test_predictions)>=vertical_splits_number*horizontal_splits_number:\n",
    "            imageNo = imageNo +1\n",
    "            tosave = torch.stack(test_predictions).detach().cpu().numpy()[0:vertical_splits_number*horizontal_splits_number]\n",
    "            test_predictions = test_predictions[vertical_splits_number*horizontal_splits_number:]\n",
    "\n",
    "            if mergemethod == \"smooth\":\n",
    "                WINDOW_SPLINE_2D = window_2D(window_size=splitsize, power=2)\n",
    "                tosave = np.moveaxis(tosave,-3,-1)\n",
    "                tosave = np.array([patch * WINDOW_SPLINE_2D for patch in tosave])\n",
    "                tosave = tosave.reshape((vertical_splits_number, horizontal_splits_number, splitsize,splitsize,1))\n",
    "                recover_Y_test_pred = recover_Image2(tosave, (im_height,im_width,1), left_pad,right_pad,top_pad,bottom_pad,overlapsize)\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                np.save(os.path.join(save_path,\"{}\".format(imageNo)),np.squeeze(recover_Y_test_pred)[UPPER_BOUND:LOWER_BOUND,:])   \n",
    "            elif mergemethod == \"average\":\n",
    "                tosave = tosave.reshape((vertical_splits_number, horizontal_splits_number, splitsize,splitsize,1))\n",
    "                recover_Y_test_pred = recover_Image(tosave, (im_height,im_width,1), left_pad,right_pad,top_pad,bottom_pad, overlapsize)\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                np.save(os.path.join(save_path,\"{}\".format(imageNo)),np.squeeze(recover_Y_test_pred)[UPPER_BOUND:LOWER_BOUND,:])\n",
    "            elif mergemethod == \"crop\":\n",
    "                tosave= crop2(tosave,48,48)\n",
    "                tosave = tosave.reshape((vertical_splits_number, horizontal_splits_number, 48,48,1))\n",
    "                recover_Y_test_pred = recover_Image(tosave, (im_height,im_width,1), left_pad-halfoverlapsize,right_pad-halfoverlapsize,top_pad-halfoverlapsize,bottom_pad-halfoverlapsize,0)\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                np.save(os.path.join(save_path,\"{}\".format(imageNo)),np.squeeze(recover_Y_test_pred)[UPPER_BOUND:LOWER_BOUND,:])\n",
    "            else:\n",
    "                print(\"please enter an valida merge method\")\n",
    "                        \n",
    "\n",
    "print(\"save\")\n",
    "t1 = time.time()\n",
    "saveResults(save_path, test_loader)\n",
    "t2 = time.time()\n",
    "print('save in {} sec'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(os.path.join(save_path,\"20.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cmapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heatmap_img = cv2.applyColorMap((a*255).astype(np.uint8), cmapy.cmap('jet_r'))\n",
    "plt.figure(figsize=(12,2))\n",
    "plt.imshow(heatmap_img[:,:,:])\n",
    "plt.axis('off')\n",
    "plt.savefig(\"{}/overlap_predictions_example/{}_XL100_{}merge_{}.png\".format(currentpath,modelname,mergemethod,testorval),bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
